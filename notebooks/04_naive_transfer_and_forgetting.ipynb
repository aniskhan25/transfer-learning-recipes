{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 04 Risky transfer and forgetting\n\nSection covered: 6 (naive aggressive updates).\n\n**Hypothesis**: full-model aggressive updates increase drift and reduce source retention."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    ROOT = Path.cwd().resolve()\n",
    "LOGS = ROOT / 'outputs' / 'logs'\n",
    "FIGS = ROOT / 'outputs' / 'figures'\n",
    "LOGS.mkdir(parents=True, exist_ok=True)\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_config(config_path: Path, use_progress: bool = True):\n",
    "    cmd = ['python', str(ROOT / 'scripts' / 'run_transfer.py'), '--config', str(config_path)]\n",
    "    if use_progress:\n",
    "        cmd.append('--use-progress')\n",
    "    subprocess.run(cmd, cwd=ROOT, check=True)\n",
    "\n",
    "def read_method(name: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(LOGS / f'transfer_{name}.csv')\n",
    "\n",
    "def deep_update(base: dict, patch: dict) -> dict:\n",
    "    for k, v in patch.items():\n",
    "        if isinstance(v, dict) and isinstance(base.get(k), dict):\n",
    "            deep_update(base[k], v)\n",
    "        else:\n",
    "            base[k] = v\n",
    "    return base\n",
    "\n",
    "def apply_fast_dev_profile(cfg: dict) -> dict:\n",
    "    cfg = deepcopy(cfg)\n",
    "    data = cfg.setdefault('data', {})\n",
    "    train = cfg.setdefault('train', {})\n",
    "\n",
    "    if 'source_train_per_class' in data:\n",
    "        data['source_train_per_class'] = min(int(data['source_train_per_class']), 220)\n",
    "    if 'source_test_per_class' in data:\n",
    "        data['source_test_per_class'] = min(int(data['source_test_per_class']), 80)\n",
    "    if 'target_train_per_class' in data:\n",
    "        data['target_train_per_class'] = min(int(data['target_train_per_class']), 30)\n",
    "    if 'target_test_per_class' in data:\n",
    "        data['target_test_per_class'] = min(int(data['target_test_per_class']), 80)\n",
    "    if 'probe_per_class' in data:\n",
    "        data['probe_per_class'] = min(int(data['probe_per_class']), 40)\n",
    "\n",
    "    data['batch_size'] = min(int(data.get('batch_size', 128)), 64)\n",
    "    data['num_workers'] = 0\n",
    "\n",
    "    if 'source_epochs' in train:\n",
    "        train['source_epochs'] = min(int(train['source_epochs']), 2)\n",
    "    if 'target_epochs' in train:\n",
    "        train['target_epochs'] = min(int(train['target_epochs']), 3)\n",
    "\n",
    "    train['gradual_schedule'] = {\n",
    "        '1': ['backbone.layer4'],\n",
    "        '2': ['backbone.layer3'],\n",
    "    }\n",
    "    return cfg\n",
    "\n",
    "def make_profiled_config(base_name: str, notebook_tag: str, fast_dev_run: bool, overrides: dict | None = None) -> Path:\n",
    "    cfg = yaml.safe_load((ROOT / 'configs' / base_name).read_text())\n",
    "    if fast_dev_run:\n",
    "        cfg = apply_fast_dev_profile(cfg)\n",
    "    if overrides:\n",
    "        cfg = deep_update(cfg, deepcopy(overrides))\n",
    "\n",
    "    suffix = 'fast' if fast_dev_run else 'full'\n",
    "    out = ROOT / 'configs' / f'tmp_{notebook_tag}_{suffix}.yaml'\n",
    "    out.write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "FAST_DEV_RUN = False\ncfg_path = make_profiled_config(\n    base_name='transfer_safe_vs_naive.yaml',\n    notebook_tag='04_naive',\n    fast_dev_run=FAST_DEV_RUN,\n    overrides={\n        'methods': ['naive_finetune'],\n        'train': {'lr_target': 0.04, 'target_epochs': 16},\n    },\n)\nrun_config(cfg_path, use_progress=not FAST_DEV_RUN)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "naive = read_method('naive_finetune')\nfig, axes = plt.subplots(1, 3, figsize=(13, 3.3))\naxes[0].plot(naive['epoch'], naive['target_test_acc'], marker='o')\naxes[0].set_title('target accuracy')\naxes[1].plot(naive['epoch'], naive['source_retention_acc'], marker='o')\naxes[1].set_title('source retention')\naxes[2].plot(naive['epoch'], naive['feature_drift'], marker='o')\naxes[2].set_title('feature drift')\nfor ax in axes:\n    ax.grid(alpha=0.2)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "naive[['epoch', 'grad_norm', 'feature_drift']].tail()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Reading this failure mode\n\n- rising gradient norm + rising drift + falling source retention indicates catastrophic forgetting risk."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
