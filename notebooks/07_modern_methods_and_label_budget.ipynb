{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 07 Modern method comparison in transfer setting\n\nSection covered: 9 (feature extraction vs fine-tuning families).\n\nExperiment matrix: label budget x method."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nfrom copy import deepcopy\nimport subprocess\nimport yaml\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nROOT = Path('..').resolve()\nLOGS = ROOT / 'outputs' / 'logs'\nFIGS = ROOT / 'outputs' / 'figures'\nLOGS.mkdir(parents=True, exist_ok=True)\nFIGS.mkdir(parents=True, exist_ok=True)\n\ndef run_config(config_path: Path, use_progress: bool = True):\n    cmd = ['python', str(ROOT / 'scripts' / 'run_transfer.py'), '--config', str(config_path)]\n    if use_progress:\n        cmd.append('--use-progress')\n    subprocess.run(cmd, cwd=ROOT, check=True)\n\ndef read_method(name: str) -> pd.DataFrame:\n    return pd.read_csv(LOGS / f'transfer_{name}.csv')\n\ndef deep_update(base: dict, patch: dict) -> dict:\n    for k, v in patch.items():\n        if isinstance(v, dict) and isinstance(base.get(k), dict):\n            deep_update(base[k], v)\n        else:\n            base[k] = v\n    return base\n\ndef apply_fast_dev_profile(cfg: dict) -> dict:\n    cfg = deepcopy(cfg)\n    data = cfg.setdefault('data', {})\n    train = cfg.setdefault('train', {})\n\n    if 'source_train_per_class' in data:\n        data['source_train_per_class'] = min(int(data['source_train_per_class']), 220)\n    if 'source_test_per_class' in data:\n        data['source_test_per_class'] = min(int(data['source_test_per_class']), 80)\n    if 'target_train_per_class' in data:\n        data['target_train_per_class'] = min(int(data['target_train_per_class']), 30)\n    if 'target_test_per_class' in data:\n        data['target_test_per_class'] = min(int(data['target_test_per_class']), 80)\n    if 'probe_per_class' in data:\n        data['probe_per_class'] = min(int(data['probe_per_class']), 40)\n\n    data['batch_size'] = min(int(data.get('batch_size', 128)), 64)\n    data['num_workers'] = 0\n\n    if 'source_epochs' in train:\n        train['source_epochs'] = min(int(train['source_epochs']), 2)\n    if 'target_epochs' in train:\n        train['target_epochs'] = min(int(train['target_epochs']), 3)\n\n    train['gradual_schedule'] = {\n        '1': ['backbone.layer4'],\n        '2': ['backbone.layer3'],\n    }\n    return cfg\n\ndef make_profiled_config(base_name: str, notebook_tag: str, fast_dev_run: bool, overrides: dict | None = None) -> Path:\n    cfg = yaml.safe_load((ROOT / 'configs' / base_name).read_text())\n    if fast_dev_run:\n        cfg = apply_fast_dev_profile(cfg)\n    if overrides:\n        cfg = deep_update(cfg, deepcopy(overrides))\n\n    suffix = 'fast' if fast_dev_run else 'full'\n    out = ROOT / 'configs' / f'tmp_{notebook_tag}_{suffix}.yaml'\n    out.write_text(yaml.safe_dump(cfg, sort_keys=False))\n    return out\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "FAST_DEV_RUN = False\nbase_name = 'transfer_core_related.yaml'\nlabel_budgets = [10, 20] if FAST_DEV_RUN else [20, 40, 80, 120]\nrows = []\n\nfor budget in label_budgets:\n    cfg_path = make_profiled_config(\n        base_name=base_name,\n        notebook_tag=f'07_budget_{budget}',\n        fast_dev_run=FAST_DEV_RUN,\n        overrides={\n            'data': {'target_train_per_class': budget},\n            'methods': ['scratch', 'feature_extraction', 'gradual_unfreeze'],\n        },\n    )\n    run_config(cfg_path, use_progress=not FAST_DEV_RUN)\n\n    for method in ['scratch', 'feature_extraction', 'gradual_unfreeze']:\n        df = read_method(method)\n        rows.append({\n            'budget': budget,\n            'method': method,\n            'best_target_acc': float(df['target_test_acc'].max()),\n            'final_target_acc': float(df['target_test_acc'].iloc[-1]),\n            'final_drift': float(df['feature_drift'].iloc[-1]),\n        })\n\nresults = pd.DataFrame(rows)\nresults.head()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "pivot = results.pivot(index='budget', columns='method', values='best_target_acc')\npivot.plot(marker='o', figsize=(6.8, 3.8), grid=True)\nplt.ylabel('best_target_acc')\nplt.title('Method ranking by target label budget')\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "results.sort_values(['budget', 'best_target_acc'], ascending=[True, False])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Interpretation\n\nFeature extraction usually wins in very low-label regimes; gradual unfreezing catches up as label budget grows."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}