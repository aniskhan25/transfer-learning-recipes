{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 05 Success vs failure transfer tasks\n\nSection covered: 7 (toy intuition to realistic split).\n\n**Hypothesis**: related source-target pairs transfer better than unrelated pairs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    ROOT = Path.cwd().resolve()\n",
    "LOGS = ROOT / 'outputs' / 'logs'\n",
    "FIGS = ROOT / 'outputs' / 'figures'\n",
    "LOGS.mkdir(parents=True, exist_ok=True)\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_config(config_path: Path, use_progress: bool = True):\n",
    "    cmd = ['python', str(ROOT / 'scripts' / 'run_transfer.py'), '--config', str(config_path)]\n",
    "    if use_progress:\n",
    "        cmd.append('--use-progress')\n",
    "    subprocess.run(cmd, cwd=ROOT, check=True)\n",
    "\n",
    "def read_method(name: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(LOGS / f'transfer_{name}.csv')\n",
    "\n",
    "def deep_update(base: dict, patch: dict) -> dict:\n",
    "    for k, v in patch.items():\n",
    "        if isinstance(v, dict) and isinstance(base.get(k), dict):\n",
    "            deep_update(base[k], v)\n",
    "        else:\n",
    "            base[k] = v\n",
    "    return base\n",
    "\n",
    "def apply_fast_dev_profile(cfg: dict) -> dict:\n",
    "    cfg = deepcopy(cfg)\n",
    "    data = cfg.setdefault('data', {})\n",
    "    train = cfg.setdefault('train', {})\n",
    "\n",
    "    if 'source_train_per_class' in data:\n",
    "        data['source_train_per_class'] = min(int(data['source_train_per_class']), 220)\n",
    "    if 'source_test_per_class' in data:\n",
    "        data['source_test_per_class'] = min(int(data['source_test_per_class']), 80)\n",
    "    if 'target_train_per_class' in data:\n",
    "        data['target_train_per_class'] = min(int(data['target_train_per_class']), 30)\n",
    "    if 'target_test_per_class' in data:\n",
    "        data['target_test_per_class'] = min(int(data['target_test_per_class']), 80)\n",
    "    if 'probe_per_class' in data:\n",
    "        data['probe_per_class'] = min(int(data['probe_per_class']), 40)\n",
    "\n",
    "    data['batch_size'] = min(int(data.get('batch_size', 128)), 64)\n",
    "    data['num_workers'] = 0\n",
    "\n",
    "    if 'source_epochs' in train:\n",
    "        train['source_epochs'] = min(int(train['source_epochs']), 2)\n",
    "    if 'target_epochs' in train:\n",
    "        train['target_epochs'] = min(int(train['target_epochs']), 3)\n",
    "\n",
    "    train['gradual_schedule'] = {\n",
    "        '1': ['backbone.layer4'],\n",
    "        '2': ['backbone.layer3'],\n",
    "    }\n",
    "    return cfg\n",
    "\n",
    "def make_profiled_config(base_name: str, notebook_tag: str, fast_dev_run: bool, overrides: dict | None = None) -> Path:\n",
    "    cfg = yaml.safe_load((ROOT / 'configs' / base_name).read_text())\n",
    "    if fast_dev_run:\n",
    "        cfg = apply_fast_dev_profile(cfg)\n",
    "    if overrides:\n",
    "        cfg = deep_update(cfg, deepcopy(overrides))\n",
    "\n",
    "    suffix = 'fast' if fast_dev_run else 'full'\n",
    "    out = ROOT / 'configs' / f'tmp_{notebook_tag}_{suffix}.yaml'\n",
    "    out.write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "FAST_DEV_RUN = False\nrelated_cfg = make_profiled_config(\n    base_name='transfer_core_related.yaml',\n    notebook_tag='05_related',\n    fast_dev_run=FAST_DEV_RUN,\n    overrides={'methods': ['gradual_unfreeze']},\n)\nrun_config(related_cfg, use_progress=not FAST_DEV_RUN)\nrelated = read_method('gradual_unfreeze').copy()\nrelated['scenario'] = 'related'\n\nunrelated_cfg = make_profiled_config(\n    base_name='transfer_unrelated_failure.yaml',\n    notebook_tag='05_unrelated',\n    fast_dev_run=FAST_DEV_RUN,\n    overrides={'methods': ['gradual_unfreeze']},\n)\nrun_config(unrelated_cfg, use_progress=not FAST_DEV_RUN)\nunrelated = read_method('gradual_unfreeze').copy()\nunrelated['scenario'] = 'unrelated'\n\nboth = pd.concat([related, unrelated], ignore_index=True)\nboth.head()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(6.5, 3.5))\nfor scenario, df in both.groupby('scenario'):\n    plt.plot(df['epoch'], df['target_test_acc'], marker='o', label=scenario)\nplt.title('Related vs unrelated transfer (same adaptation policy)')\nplt.xlabel('epoch')\nplt.ylabel('target_test_acc')\nplt.grid(alpha=0.2)\nplt.legend(frameon=False)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "summary = both.groupby('scenario').agg(\n    final_target_acc=('target_test_acc', 'last'),\n    final_retention=('source_retention_acc', 'last'),\n    final_drift=('feature_drift', 'last'),\n).reset_index()\nsummary\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Interpretation\n\nTask alignment is visible as a shift in the full stability profile, not only endpoint accuracy."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
