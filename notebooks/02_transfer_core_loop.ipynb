{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 02 Transfer loop: source to target\n\nSections covered: 3-4 (core idea and universal loop).\n\n**Hypothesis**: reusing source representation improves sample efficiency vs scratch."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nfrom copy import deepcopy\nimport subprocess\nimport yaml\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nROOT = Path('..').resolve()\nLOGS = ROOT / 'outputs' / 'logs'\nFIGS = ROOT / 'outputs' / 'figures'\nLOGS.mkdir(parents=True, exist_ok=True)\nFIGS.mkdir(parents=True, exist_ok=True)\n\ndef run_config(config_path: Path, use_progress: bool = True):\n    cmd = ['python', str(ROOT / 'scripts' / 'run_transfer.py'), '--config', str(config_path)]\n    if use_progress:\n        cmd.append('--use-progress')\n    subprocess.run(cmd, cwd=ROOT, check=True)\n\ndef read_method(name: str) -> pd.DataFrame:\n    return pd.read_csv(LOGS / f'transfer_{name}.csv')\n\ndef deep_update(base: dict, patch: dict) -> dict:\n    for k, v in patch.items():\n        if isinstance(v, dict) and isinstance(base.get(k), dict):\n            deep_update(base[k], v)\n        else:\n            base[k] = v\n    return base\n\ndef apply_fast_dev_profile(cfg: dict) -> dict:\n    cfg = deepcopy(cfg)\n    data = cfg.setdefault('data', {})\n    train = cfg.setdefault('train', {})\n\n    if 'source_train_per_class' in data:\n        data['source_train_per_class'] = min(int(data['source_train_per_class']), 220)\n    if 'source_test_per_class' in data:\n        data['source_test_per_class'] = min(int(data['source_test_per_class']), 80)\n    if 'target_train_per_class' in data:\n        data['target_train_per_class'] = min(int(data['target_train_per_class']), 30)\n    if 'target_test_per_class' in data:\n        data['target_test_per_class'] = min(int(data['target_test_per_class']), 80)\n    if 'probe_per_class' in data:\n        data['probe_per_class'] = min(int(data['probe_per_class']), 40)\n\n    data['batch_size'] = min(int(data.get('batch_size', 128)), 64)\n    data['num_workers'] = 0\n\n    if 'source_epochs' in train:\n        train['source_epochs'] = min(int(train['source_epochs']), 2)\n    if 'target_epochs' in train:\n        train['target_epochs'] = min(int(train['target_epochs']), 3)\n\n    train['gradual_schedule'] = {\n        '1': ['backbone.layer4'],\n        '2': ['backbone.layer3'],\n    }\n    return cfg\n\ndef make_profiled_config(base_name: str, notebook_tag: str, fast_dev_run: bool, overrides: dict | None = None) -> Path:\n    cfg = yaml.safe_load((ROOT / 'configs' / base_name).read_text())\n    if fast_dev_run:\n        cfg = apply_fast_dev_profile(cfg)\n    if overrides:\n        cfg = deep_update(cfg, deepcopy(overrides))\n\n    suffix = 'fast' if fast_dev_run else 'full'\n    out = ROOT / 'configs' / f'tmp_{notebook_tag}_{suffix}.yaml'\n    out.write_text(yaml.safe_dump(cfg, sort_keys=False))\n    return out\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "FAST_DEV_RUN = False\ncfg_path = make_profiled_config(\n    base_name='transfer_core_related.yaml',\n    notebook_tag='02_core_loop',\n    fast_dev_run=FAST_DEV_RUN,\n)\nrun_config(cfg_path, use_progress=not FAST_DEV_RUN)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def plot_compare(metric: str, methods):\n    plt.figure(figsize=(6, 3.5))\n    for m in methods:\n        df = read_method(m)\n        plt.plot(df['epoch'], df[metric], marker='o', label=m)\n    plt.xlabel('epoch')\n    plt.ylabel(metric)\n    plt.legend(frameon=False)\n    plt.grid(alpha=0.2)\n\nplot_compare('target_test_acc', ['scratch', 'feature_extraction', 'gradual_unfreeze', 'naive_finetune'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "summary = []\nfor m in ['scratch', 'feature_extraction', 'gradual_unfreeze', 'naive_finetune']:\n    df = read_method(m)\n    summary.append({\n        'method': m,\n        'best_target_acc': float(df['target_test_acc'].max()),\n        'final_target_acc': float(df['target_test_acc'].iloc[-1]),\n        'final_feature_drift': float(df['feature_drift'].iloc[-1]),\n    })\npd.DataFrame(summary).sort_values('best_target_acc', ascending=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Loop mapping\n\n- `source pretrain` creates `theta_s`.\n- each method initializes target training from either random (`scratch`) or `theta_s` (transfer methods).\n- adaptation policy is the only variable changed."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}